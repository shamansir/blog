<!DOCTYPE html>

<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta charset="utf-8" />

<meta name="author" content="Ulric Wilfred" />
<meta name="description" content="Блог о программировании и только о нём. Ни слова о луке. Ни одного. Вообще." />
<meta name="generator" content="mynt v0.2.3-dev" />

<link rel="author me ext" href="http://shamansir.github.com" />
<link rel="contents start home" href="/blog/ru/" />
<link rel="index" href="/blog/ru/archives/" />

<link rel="shortcut icon" href="/blog/ru/assets/img/favicon.png" type="image/x-icon" />

<link rel="alternate" href="/blog/ru/feed.xml" type="application/atom+xml" />

<link rel="stylesheet" href="/blog/ru/assets/css/screen.css" media="screen, projection" type="text/css" />
<link rel="stylesheet" href="/blog/ru/assets/css/print.css" media="print" type="text/css" />
  <!--[if IE]>
      <link rel="stylesheet" href="/blog/ru/assets/css/ie.css" media="screen, projection" type="text/css" />
  <![endif]-->
<link rel="stylesheet" href="/blog/ru/assets/css/pygments.trac.css" type="text/css" />

<!-- Font Awesome - http://fortawesome.github.com/Font-Awesome -->
<link rel="stylesheet" href="/blog/ru/assets/css/font-awesome.css" />


    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-20770637-6']);
        _gaq.push(['_trackPageview']);
        
        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

    
    <title>nwao — Путь радуги: Алгоритм распознавания движений пальцев рук на основе цветовой диффференциации (Driven by LISP) &ndash; Ни слова о луке</title>

</head>

<body>
    <div id="nwao-page">
        <div id="nwao-header">
            <div id="nwao-holder">
                <nav id="nwao-nav"><ul>
                    <li><a href="/blog/ru/" rel="contents" title="Блог"><i class="icon-home"></i>&nbsp;Блог</a></li>
                    <li><a href="/blog/ru/archives/" rel="index" title="Архив"><i class="icon-book"></i>&nbsp;Архив</a></li>
                    <li><a href="http://shamansir.github.com" rel="author" title="Автор"><i class="icon-user"></i>&nbsp;Автор</a></li>
                    <!-- TODO: TAGS PAGE -->
                    <li><a href="/blog/ru/feed.xml" title="Лента"><i class="icon-rss"></i>&nbsp;RSS</a></li>
                </ul></nav>

                <h1 id="nwao-title"><a href="/blog/ru/" title="Ни слова о луке">&raquo;Ни слова о луке&laquo;</a></h1>
            </div>
            <div id="nwao-subtitle"><span>сэр шаман рассказывает о чём может</span></div>
        </div>

        <!--
        <nav>
          <div id="nwao-dive">
            <a href="#" id="nwao-prev">← Предыдущий пост</a><span> | </span>
            <a href="#" id="nwao-next">Следующий пост →</a>
          </div>
        </nav>
        -->
        
        <div id="nwao-content">
            
    <article id="nwao-post">
        <div class="nwao-post-header">
            <h2 class="nwao-post-title" id="top">
                <a href="#top" title="Путь радуги: Алгоритм распознавания движений пальцев рук на основе цветовой диффференциации (Driven by LISP)">
                    Путь радуги: Алгоритм распознавания движений пальцев рук на основе цветовой диффференциации (Driven by LISP)
                </a>
            </h2>
            <dl>
    <dt class="nwao-hidden">Опубликован</dt>
    <dd class="nwao-published"><i class="icon-time"></i>&nbsp;12 августа 2010, четверг</dd>
    
    <dt class="nwao-hidden">Тэги</dt>
    <dd class="nwao-tags">
    
        <a href="/blog/ru/tags/algorithm/" rel="tag" title="Посты с тэгом 'algorithm'"><i class="icon-tag"></i>&nbsp;algorithm</a><span class="nwao-hidden">,</span> 
    
        <a href="/blog/ru/tags/lisp/" rel="tag" title="Посты с тэгом 'lisp'"><i class="icon-tag"></i>&nbsp;lisp</a><span class="nwao-hidden">,</span> 
    
        <a href="/blog/ru/tags/nijiato/" rel="tag" title="Посты с тэгом 'nijiato'"><i class="icon-tag"></i>&nbsp;nijiato</a><span class="nwao-hidden">,</span> 
    
        <a href="/blog/ru/tags/vision/" rel="tag" title="Посты с тэгом 'vision'"><i class="icon-tag"></i>&nbsp;vision</a>
    
    </dd>
    
</dl>
        </div>
        
        <div class="nwao-post-content">
            <p>Я немного безумный и в свободное время занялся изучением LISP&#39;а и, чтобы сделать обучение немного интереснее, попробовал реализовать самоизобретённый алгоритм. &ldquo;Алгоритм&rdquo; - это, конечно, громко сказано, в нём нет ни перемножений матриц, ни сортировки массивов, ни пузырьков, ни долгой работы над оптимизацией (ни даже калибровки цветов, оправдываюсь тем, что версия учебная). И да, в статье много картинок, а в конце даже будет видео.</p>

<p><a href="http://code.google.com/p/nijiato">Заранее ссылка на исходники</a></p>

<p>Цель проста: Определять положение всех десяти пальцев в пространстве (координаты положения и угол наклона каждого пальца в дискретный момент), выдавать эти данные через <code>stdout</code> или по сокету другой программе, а та сможет делать предположения о &ldquo;гесчурах&rdquo;, которые совершает пользователь и соответственно им реагировать на пользовательском интерфейсе. Вдохновлением для идеи послужил ролик на хабре <a href="http://habrahabr.ru/blogs/ui_design_and_usability/95590/">про будущее интерфейсов</a> и то что, как нельзя кстати, под руку попались <a href="http://www.cliki.net/CL-V4L2">биндинги video4linux для Common Lisp</a> от Виталия Маяцких. Здесь я представляю вам первую часть - программу, которая определяет координаты и угол наклона пальцев. Не знаю, дойдут ли руки до написания остальных и приведения в энтерпрайзное состояние этой, если никто не сподобится поучаствовать.</p>

<p>Особенность этого способа в том, что он, при должной смелости, воспроизводим в домашних условиях. Для определения положений пальцев в пространстве не используется датчиков, эвристических алгоритмов и паттерн-матчинга как в OpenCV. Используются:</p>

<ul>
<li>Linux</li>
<li>Lisp-интерпретатор, предпочтительно SBCL</li>
<li><a href="http://code.google.com/p/nijiato/wiki/RequiredCLpackages">Куча Common-Lilsp-овых пакетов</a> (хотя многие из них у вас могут быть уже установлены, если вы работаете с Lisp)</li>
<li>Драйвер video4linux (<code>v4l2convert.so</code>) и поддержка GTK</li>
<li>Любая веб-камера, совместимая с video4linux (у меня - Genius iSlim 300)</li>
<li>Десять разноцветных бумажек, которые можно надеть на пальцы: по две красных, оранжевых, жёлтых, зелёных и голубых.</li>
</ul>

<p>Эти бумажки и есть основа этого безумного алгоритма, без остальных частей его можно реализовать на любом языке прораммирования и на любом окружении. <a href="http://code.google.com/p/nijiato/source/browse/nijiato-recognition.lisp">Исходный код алгоритма расположен здесь</a>, можно следить за описанием и кодом одновременно. Lisp считается самодокументируемым языком, так что, надеюсь, всё будем понятно :).</p>
<h3 id="ку.-исходные-данные"><a href="#ку.-исходные-данные" title="Ку. Исходные данные">Ку. Исходные данные</a></h3>
<p>Вначале необходимо определить цвета, при обнаружении которых программа будет понимать, что <em>возможно</em> в этом месте находится палец. Точные цвета задавать бессмысленно, необходимо ввести какую-то дельту, узкий размах возможных значений, чтобы при необходимости в &ldquo;подозрительный&rdquo; регион попала и немного затенённая область и немного осветлённая, примерно того же цвета. Я задавал для каждого цвета свою собственную дельту, поскольку каждый из них обычно ведёт себя по-разному. Все мои значения &ldquo;захардкожены&rdquo; - определены опытным путём для определённого освещения в определённое время суток (программа хорошо работает у меня дома, при включенном свете с 20 часов до глубокой ночи, при яркости камеры по умолчанию - как раз когда я возвращаюсь с работы). Будем считать, что это учебная версия и это оправдывает меня. Можно добавить предварительную калибровку или анализирование общей освещённости кадра и &ldquo;подправку&rdquo; цветов в соответствии с этим значением, но сами бумажки в любом случае будут у всех разных оттенков, если только не начинать завтра же их массовое производство с идентичными цветами, привитыми им на заводе.</p>

<p>Итак, надеваем на каждый палец по бумажке.</p>

<p><img src="/blog/ru/figures/nijiato-detection-of-fingers-motion-algorithm/colors.png" alt="Color values"></p>

<p>На картинке RGB-компоненты представлены в диапазонах от нуля до единицы, overflow при сложении/вычитании дельты не учитывается. Кроме того, эти цвета индивидуальны для моего случая, поэтому так непохожи на идеальные.</p>
<h3 id="ку.-первый-проход.-определение-участков-возможного-нахождения-пальцев."><a href="#ку.-первый-проход.-определение-участков-возможного-нахождения-пальцев." title="Ку. Первый проход. Определение участков возможного нахождения пальцев.">Ку. Первый проход. Определение участков возможного нахождения пальцев.</a></h3>
<p>В программе используется массив <code>*fingers-values*</code> длиной (ширина кадра * высоту кадра), каждая ячейка которого соответствует одному пикселю кадра и будет содержать число от <code>0</code> до <code>200</code>. На каждом следующем кадре этот массив полностью заполняется новыми значениями на основе проанализированных RGB-компонентов пикселей.</p>

<p>Так, в процессе работы алгоритма в массиве <code>*fingers-values*</code> будут находиться значения:</p>

<ul>
<li>Значение <code>0</code> - несоответствие пикселя ни одному из цветов плюс-минус дельта</li>
<li>Значения от <code>1</code> до <code>49</code> - это значения для предполагаемых областей нахождения пальцев левой руки, по <code>9-10</code> на каждый палец.</li>
<li>Значения от <code>50</code> до <code>99</code> -это значения для предполагаемых областей нахождения пальцев правой руки, по <code>10</code> на каждый палец.</li>
<li>Значения больше <code>100</code> и меньше <code>200</code> - точное нахождение соответсвующего пальца, для того чтобы узнать какого - надо вычесть <code>100</code>.</li>
</ul>

<p>Теперь можно вернуться к алгоритму, запускаем первый проход - попиксельно анализируем текущий кадр изображения.</p>

<p>Если пиксель не раскрашен ни одним цветом из определённых выше плюс-минус дельта, в ячейку массива <code>*fingers-values*</code> записывается <code>0</code>. Если это <em>предположительно</em> какой-то конкретный палец (цвет пикселя совпадает с одним из предопределённых цветов), в массив записывается соответствующее число - <code>1-9</code> для большого пальца, <code>10-19</code> для указательного, <code>20-29</code> для среднего, <code>30-39</code> для безымянного и <code>40-49</code> для мизинца. Сейчас в ячейки записываются только значения <code>9</code>,<code>19</code>, <code>29</code>, <code>39</code>, <code>49</code> - я рассчитывал сделать дополнительную градацию в зависимости от того, насколько близко к &ldquo;среднему&rdquo; цвету оказалось значение, но это оказалось не нужно (однако диапазоны по 10 сильно помогают в дальнейшем). По умолчанию считается, что найдены пальцы левой руки. Количество найденых участков одного цвета на этом этапе никак не контролируется и не регулируется.</p>

<p><img src="/blog/ru/figures/nijiato-detection-of-fingers-motion-algorithm/values.png" alt="Сorrespondence of colors and fingers"></p>

<p>Это всё, кадр просканирован, массив заполнен, однако это только первый этап, <em>в массиве значения меньше <code>50</code></em>.</p>
<h3 id="ку.-второй-проход.-определение-координат-и-углов."><a href="#ку.-второй-проход.-определение-координат-и-углов." title="Ку. Второй проход. Определение координат и углов.">Ку. Второй проход. Определение координат и углов.</a></h3>
<p>Перед вторым проходом кадра создаётся временный массив из 10 булевых переменных <code>hits</code>, в нём мы контролируем, какие пальцы уже были определены. Теперь мы поочерёдно проходим по каждой ячейке главного массива <code>*fingers-values*</code>. Если значение текущей ячейки главного массива больше нуля и меньше <code>100</code>, то мы проверяем, не был ли такой палец уже определён, если был - то пропускаем ячейку, если нет - пытаемся сделать предположение о том, какая это может быть рука на основе координаты <code>x</code> для этой ячейки - если уже был найден такой же палец левой руки и его координата <code>x</code> оказалась больше чем текущая (но не на слишком близком расстоянии, у меня - не менее <code>80px</code>), то похоже, мы имеем дело с правой рукой, тогда мы прибавляем к текущему значению <code>50</code> и работаем с уже обновлённым.</p>

<p><img src="/blog/ru/figures/nijiato-detection-of-fingers-motion-algorithm/distance.png" alt="Distance between fingers"></p>

<p>Теперь у мы знаем руку и предположительную область нахождения пальца, осталось определить его координаты. Для этого запоминаем координаты <code>x</code> и <code>y</code> текущей точки, в цикле по углам от <code>0</code> до <code>pi</code>, с шагом, например, <code>pi / 20</code>, вычисляем координаты пикселей для каждого из лучей с соответсвующим углом, простирающихся из этой точки (в не-учебной версии заранее вычисленные относительные координаты можно и закэшировать), длина лучей равна заранее установленному числу, у меня это <code>31px</code> (включая текущий пискель, вверх и вниз по 15), а их центр расположен в текущей точке.</p>

<p><img src="/blog/ru/figures/nijiato-detection-of-fingers-motion-algorithm/angles.png" alt="Angles detection algorythm"></p>

<p>Координаты пикселей каждого из лучей однозначно соответствуют индексам соответсвующих соседних ячеек в массиве <code>*fingers-values*</code>. Оставаясь курсором на текущей точке, мы подсчитываем попиксельно для каждого из лучей количество совпавших значений (те, которые от <code>1</code> до <code>50</code>, прибавляя <code>50</code> если это правая рука), если это количество является допустимым для такой длины луча (я разрешаю ошибку в 4 пикселя, то есть совпасть должны 27 пикслей из 31-го), то бинго - <strong>мы определили угол и положение пальца</strong>: координаты пальца (условные) - это начальная и конечная координаты луча, угол наклона пальца - это угол луча, который совпал. Можно записать в <code>*hits*</code>, что палец найден и вывести на экран (или в <code>stdout</code>) данные.</p>

<p><img src="/blog/ru/figures/nijiato-detection-of-fingers-motion-algorithm/smile.png" alt="Smile"></p>
<h3 id="ку.-возможные-применения"><a href="#ку.-возможные-применения" title="Ку. Возможные применения">Ку. Возможные применения</a></h3>
<p>Когда есть координаты пальцев и углы их наклона, можно анализировать практически любые &ldquo;гесчуры&rdquo;. Правда, от анализатора будет требоваться умение &ldquo;предсказывать&rdquo; положения на основе предыдущих состояний - если палец скрылся из вида, то может быть рука была сжата в кулак или было совершено быстрое движение вовне кадра. Есть решаемая проблема с определением какой руке принадлежит палец, её можно решить засчёт дополнительных маркеров на ладонях рук (если не видно маркера, а пальцы идут в кадре в обратном порядке - то это тыльная сторона), как раз остаются синий и фиолетовый цвета (я их добавил на картинки для наглядности), или можно вообще не принимать во внимание для &ldquo;гесчурсов&rdquo;, какая это рука, если недостаточно данных (в камеру видно только два пальца). Эти &ldquo;гесчуры&rdquo; можно использовать для управления интерфейсами как в <a href="http://habrahabr.ru/blogs/ui_design_and_usability/95590/">упомянутой статье</a> - переноса окон, перебора картинок в альбомах, вообще управления интерфейсом, чтобы всё было как в Minority Report, при этом нужна только камера и преодоление психологического барьера, чтобы вырезать и надеть на пальцы цветные бумажки (или подобные контроллеры). Это пока что дешевле чем датчики и пока что веселее чем существующие применения Microsoft Kinect :).</p>

<p><strong>Upd.</strong> Люди поделились со мной <a href="http://blog.makezine.com/archive/2010/07/gestural_interface_via_flamboyant_g.html">этим видео</a>, идея очень похожа, но у меня более чердачная версия всё равно :). И время прошло и Microsoft Kinect стал делать намного более интересные вещи, так что извини меня Microsoft Kinect :)</p>
<h3 id="ку.-что-улучшить"><a href="#ку.-что-улучшить" title="Ку. Что улучшить">Ку. Что улучшить</a></h3>
<ul>
<li>Добавить калибровку, оценивать уровень освещения, ввести девайс &ldquo;цветная бумажка Nijiato&rdquo; в массовое производство</li>
<li>Более разумно определять какую руку видно в камеру, например по дополнительной бумажке на ладони и на основе расположения пальцев (если нет бумажки - это тыльная сторона рук</li>
<li>Много оптимизации:

<ul>
<li>можно кэшировать относительные координаты лучей</li>
<li>сделать вычисления поточными</li>
<li>можно сканировать не каждый кадр, а каждый десятый, быстрые движения при этом &ldquo;додумывать&rdquo; на этапе анализирования &ldquo;гесчурсов&rdquo;</li>
<li>&hellip;</li>
</ul></li>
</ul>
<h3 id="ку.-пояснения-по-программе"><a href="#ку.-пояснения-по-программе" title="Ку. Пояснения по программе">Ку. Пояснения по программе</a></h3>
<p>На данный момент необходимо установить и зарегистрировать в ADSF пакеты из <a href="http://code.google.com/p/nijiato/source/browse/requirements">этого списка</a> (там указаны репозитории и необходимые команды), установить пакет <code>libv4l-dev</code> и <code>libgtkglext</code>. Также можно установить <code>rlwrap</code> для более удобной работы с интерпретатором. Если система 64-битная, нужно будет убрать хак из биндингов CL-V4L2, это также описано в <a href="http://code.google.com/p/nijiato/source/browse/requirements">requirements</a>.</p>

<p>После выполнения этих операций запуск прост:</p>
<pre><code>$ LD_PRELOAD=/usr/lib/libv4l/v4l2convert.so [rlwrap] sbcl
* (load &#34;nijiato-demo-load.lisp&#34;)
</code></pre>
<p>(<code>.so</code>-файл может лежать в другом месте, в зависимости от устройства и битности вашей операционной системы)</p>

<p>Программа использует для запуска переработанный демо-пример из <code>CL-V4L2</code>, который показывает GTK-окно и проецирует на него OpenGL-текстуру с изображением с камеры, а также позволяет считывать пиксели на каждом фрейме. FASL-версия может не запуститься, с этой проблемой я борюсь.</p>
<h3 id="ку.-видео"><a href="#ку.-видео" title="Ку. Видео">Ку. Видео</a></h3>
<p>И наконец видео с работой программы, при старте загружается много библиотек, можно промотать первые секунд 30. &ldquo;Определённые&rdquo; положения пальцев отображаются тонкой однопиксельной чёрной линией (те самые совпавшие лучи) и выводятся в консоль в читаемом виде. В середине видео не определяется два больших пальца разных рук, это из-за того, что они расстояние между ними меньше 80 пикселей, которые я задал как минимальную ширину между руками. Окно, которое берётся из камеры намеренно маленькое, чтобы программа не так сильно тормозила :).</p>

<p><a href="http://vimeo.com/14073181"><img src="/blog/ru/figures/nijiato-detection-of-fingers-motion-algorithm/vimeo-video-frame.png" alt="Link to Vimeo video"></a></p>

        </div>
    </article>

        </div>
        
        
            <ul id="nwao-social">
    <li><a href="https://twitter.com/#!/shaman_sir" title="профиль в Twitter"><img src="/blog/ru/assets/img/social/twitter.png" width="16" height="16" alt="профиль в Twitter"></a></li>
    <li><a href="https://github.com/shamansir" title="профиль на Github"><img src="/blog/ru/assets/img/social/github.png" width="16" height="16" alt="профиль на Github"></a></li>                
    
    <li><a href="https://www.facebook.com/shaman.sir" title="профиль в Facebook"><img src="/blog/ru/assets/img/social/facebook.png" width="16" height="16" alt="профиль в Facebook"></a></li>
    
    
    <li><a href="http://stackoverflow.com/users/167262" title="профиль на Stackoverflow"><img src="/blog/ru/assets/img/social/stack-overflow.png" width="16" height="16" alt="профиль на Stack Overflow"></a></li>
    
</ul>
        

        <div id="nwao-footer">
            <p>Copyright &copy; 2012 Ulric Wilfred &ndash; запитано <a href="http://mynt.mirroredwhite.com/">mynt</a></p>
        </div>

        <div id="nwao-jump-to-top"><a href="#top" title="Вира!">&#x2912;</a></div>

        <!--
        <script type="text/javascript" src="/blog/ru/assets/js/scrolls.js"></script>
        <script type="text/javascript" src="/blog/ru/assets/js/page.scrolls.js"></script> -->


        </script>
    </div>

    <div id="nwao-onion"></div>
</body>
</html>